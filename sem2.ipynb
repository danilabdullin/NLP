{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "J5YiZNCPLVPe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "DFLtXAZ-LVPq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dany\\AppData\\Local\\Temp\\ipykernel_26936\\3125191635.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = positive.append(negative)\n"
     ]
    }
   ],
   "source": [
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "df = positive.append(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "j1AEISlBLVP0",
    "outputId": "443eadf2-9df4-4507-f2a5-a64f7968182f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111918</th>\n",
       "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111919</th>\n",
       "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111920</th>\n",
       "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111921</th>\n",
       "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111922</th>\n",
       "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text     label\n",
       "111918  Но не каждый хочет что то исправлять:( http://...  negative\n",
       "111919  скучаю так :-( только @taaannyaaa вправляет мо...  negative\n",
       "111920          Вот и в школу, в говно это идти уже надо(  negative\n",
       "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...  negative\n",
       "111922  Такси везет меня на работу. Раздумываю приплат...  negative"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "ZWta7oDgLVP8"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAapBC7VLVQC"
   },
   "source": [
    "## Baseline: классификация необработанных n-грамм\n",
    "\n",
    "### Векторизаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "M-AvVt8XLVQD"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # можно заменить на любимый классификатор\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSuoVoxcLVQI"
   },
   "source": [
    "Что такое n-граммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "zeNA7732LVQJ"
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NeApDOmrLVQN",
    "outputId": "d8c763fe-2658-47ac-fcee-5b7bbe49f0d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если',), ('б',), ('мне',), ('платили',), ('каждый',), ('раз',)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Если б мне платили каждый раз'.split()\n",
    "list(ngrams(sent, 1)) # униграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPAS0fS-LVQQ",
    "outputId": "aa3ae031-c661-4639-b7ab-f93ba1b6cee5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б'),\n",
       " ('б', 'мне'),\n",
       " ('мне', 'платили'),\n",
       " ('платили', 'каждый'),\n",
       " ('каждый', 'раз')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 2)) # биграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d77jmVPhLVQU",
    "outputId": "c8de801b-8efc-437e-8673-4e9e31665ea5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне'),\n",
       " ('б', 'мне', 'платили'),\n",
       " ('мне', 'платили', 'каждый'),\n",
       " ('платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 3)) # триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5xXTBrGELVQX",
    "outputId": "f5b423d9-db6b-4efa-8bfa-a446a55ee018"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне', 'платили', 'каждый'),\n",
       " ('б', 'мне', 'платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 5)) # ... пентаграммы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHGJBEm-LVQb"
   },
   "source": [
    "Самый простой способ извлечь фичи из текстовых данных -- векторизаторы: `CountVectorizer` и `TfidfVectorizer`\n",
    "\n",
    "Объект `CountVectorizer` делает простую вещь:\n",
    "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грам во всём корпусе\n",
    "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "eMqZFBTgLVQb"
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train) # bow -- bag of words (мешок слов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZkpqVtILVQe"
   },
   "source": [
    "ngram_range отвечает за то, какие n-граммы мы используем в качестве фичей:<br/>\n",
    "ngram_range=(1, 1) -- униграммы<br/>\n",
    "ngram_range=(3, 3) -- триграммы<br/>\n",
    "ngram_range=(1, 3) -- униграммы, биграммы и триграммы.\n",
    "\n",
    "В vec.vocabulary_ лежит словарь: мэппинг слов к их индексам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWRtOSzKLVQf",
    "outputId": "668857b0-def2-4547-8fd5-014fe3858bec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kilz0x33d', 46422),\n",
       " ('затишье', 136743),\n",
       " ('перед', 180200),\n",
       " ('буряй', 108901),\n",
       " ('нам', 163272)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vec.vocabulary_.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170125,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkmX3iBbLVQi",
    "outputId": "5bbb432e-1c45-422a-edc2-60841ef0ee33"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=170126, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=170126, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=170126, random_state=42)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42, max_iter=170126 )\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJ8q5_59LVQm",
    "outputId": "d88c6de2-640a-4cc9-ae95-29fe12c80131"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.76      0.77     28463\n",
      "    positive       0.76      0.78      0.77     28246\n",
      "\n",
      "    accuracy                           0.77     56709\n",
      "   macro avg       0.77      0.77      0.77     56709\n",
      "weighted avg       0.77      0.77      0.77     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAhgaYgqLVQp"
   },
   "source": [
    "Попробуем сделать то же самое для триграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPWXlh6ALVQq",
    "outputId": "094a7189-bc36-42df-81ee-f599a206ca0c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dany\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.57      0.68     41451\n",
      "    positive       0.39      0.73      0.50     15258\n",
      "\n",
      "    accuracy                           0.61     56709\n",
      "   macro avg       0.62      0.65      0.59     56709\n",
      "weighted avg       0.73      0.61      0.64     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(3, 3))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170125, 1326842)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnfyJkzTLVQu"
   },
   "source": [
    "(как вы думаете, почему в результатах теперь такой разброс по сравнению с униграммами?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# потому что фичей во втором случае получается больше 1 миллиона, соответсвенно матрица более разряженная\n",
    "# и модель переобучается"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJABxhalLVQu"
   },
   "source": [
    "## TF-IDF векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LJES2s-LVQv"
   },
   "source": [
    "`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений – tf-idf каждого слова.\n",
    "\n",
    "Как считается tf-idf:\n",
    "\n",
    "TF (term frequency) – относительная частотность слова в документе:\n",
    "$$ TF(t,d) = \\frac{n_t}{\\sum_k n_k} $$\n",
    "\n",
    "`t` -- слово (term), `d` -- документ, $n_t$ -- количество вхождений слова, $n_k$ -- количество вхождений остальных слов\n",
    "\n",
    "IDF (inverse document frequency) – обратная частота документов, в которых есть это слово:\n",
    "$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
    "\n",
    "`t` -- слово (term), `D` -- коллекция документов\n",
    "\n",
    "Перемножаем их:\n",
    "$$TFIDF_(t,d,D) = TF(t,d) \\times IDF(i, D)$$\n",
    "\n",
    "Сакральный смысл – если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом \n",
    "количестве документов, у него высокий TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FmEcRD28LVQ0"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AWLhMl9xLVQ3",
    "outputId": "054e5662-1c41-42f6-92e4-ce0194317ce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.77      0.75     26898\n",
      "    positive       0.78      0.76      0.77     29811\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTODTRnKLVQ6"
   },
   "source": [
    "В этот раз получилось хуже :( Вернёмся к `CountVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8v9Scpn9Y0M"
   },
   "source": [
    "## PMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVRqLcSY0etj"
   },
   "source": [
    "Можно оценить взаимосвязь слов в корпусе и понять, какие биграммы наиболее часто встречаются в тексте. Для этого можно использовать метрику PMI (Pointwise Mutual Information) - поточечная взаимная информация. Метрика PMI для двух слов вычисляется по формуле:\n",
    "\n",
    "$$pmi(x; y) = log \\frac{p(x,y)}{p(x)p(y)} $$\n",
    "\n",
    "Здесь p(y|x) - вероятность встретить слово $y$ после $x$, $p(y)$ - вероятность встретить слово $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXgDwf6W6Kk5"
   },
   "source": [
    "Оценим важность биграмм в нашем обучающем корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKmiOEaW53F9",
    "outputId": "96a85968-e0cb-4b17-cd62-bc3de5e3e9b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package genesis to\n",
      "[nltk_data]     C:\\Users\\dany\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package genesis is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "[('+375447167151', 'звоги'), ('+СОННО', '+НЕ'), ('+погода', 'крутая='), (',4', 'запирайте'), (',Дела', 'рез'), ('-10,11', 'болсо'), ('-163', '-КРАСНЫЙ'), ('-165', '-СИНИЙ'), ('-53', 'dBm'), ('-700', 'рублей.-А'), ('-800', 'нахууй'), ('-АХАХАХАХ', 'ЮБКУ'), ('-АХАХАХАХХАХАХАХАХАХХА', '-АХАХАХХАХАХАХАХАХ'), ('-Айгуль', 'Маратовна'), ('-Алина', '-Синие'), ('-Аха', 'спетросянил'), ('-ВСЕМ', 'СПОКОЙНЫХ'), ('-Вам', 'завернуть'), ('-Весело', 'кншн:3'), ('-Вообще-то', '3.Я'), ('-Восьмигрудый', 'трипи'), ('-Время', 'эмокора'), ('-Выздоравливай', 'педрилк'), ('-ГНИДОТА', '-Над'), ('-Д-Д-Д-Д-Д-Д-ДРОП', 'ЗЭ'), ('-ДЕТЕЙ', 'НАКРЫЛО'), ('-ДОВАЙТИ', 'АЛДСКУЛ'), ('-Домашка', '-кл.час'), ('-ЖАРЕНЫЙ', 'КАРТОФЕЛЬ'), ('-ЗАШЛА', 'ОДЕЛА'), ('-Защитано', '-ес'), ('-Зелено-карие', '-Киллджой'), ('-КРАСНЫЙ', '-ЧЕРНЫЕ'), ('-Керем', 'севгили'), ('-Киллджой', '-Котик'), ('-Маладец', '-Лол'), ('-НА', 'РЕАЛЬНЫХ'), ('-НАЧИНАЕТ', 'БЕСИТЬ'), ('-ОЗВУЧИВАТЕЛЬ', 'МУЛЬТИКОВ'), ('-Олесь', '-Пошёл'), ('-Песня', 'грусная='), ('-Поэзия', 'заключает'), ('-ПриФетиГг', 'СолНыСко='), ('-Рыбу', 'соленую'), ('-СИНИЙ', '-БЕЛЫЕ'), ('-Серые', '-НЕМЕЦКИЕ'), ('-Танцы', '-Хорошие'), ('-Ти', 'кантужена'), ('-Тиць', 'дурне'), ('-Трахався', '-Іди'), ('-Филл', '-познакомились'), ('-ШАПКА', '-ФОН'), ('-Юлия', 'Зазулина'), ('-Я.банан', '-ахх'), ('-анал', '-абстиненция'), ('-анатолий', 'николаевич'), ('-бляя', 'хммммммм'), ('-водичку', 'лью'), ('-г', 'үзээ'), ('-говорит', 'одноногий'), ('-дак', 'Бася'), ('-дерьмо', 'редкосное'), ('-иногда', '.Ностальгирую'), ('-киллджой', '-шатенка'), ('-кучи', 'мутики'), ('-ладно', '-АХАХАХАХХАХАХАХАХАХХА'), ('-ложусь', 'спать-темно'), ('-любому', 'умрёшь'), ('-мега', 'шизофреничная'), ('-напиши', '-нит'), ('-наш', 'класс^^'), ('-патлатые', '-лысый'), ('-пиши', 'Ненси'), ('-попробуй', 'помедитировать'), ('-раз', 'плёткой'), ('-распускаю', 'волосы-'), ('-руу', 'орох'), ('-рүү', 'мэншндсэн'), ('-спрашивает', 'жена.-У'), ('-столько', 'бабосов'), ('-ти', 'классников'), ('-удивительная', 'штука.Его'), ('-хаски', '-розовое'), ('-цвета', 'Магнита'), ('-цитирую', 'гастролога'), ('-цытата', 'Шимы'), ('-черные', '-аниме'), ('-ыг', 'үгүйсгэж'), ('-эртага', 'бозорга'), ('-языком', 'владеешь'), ('.NET', 'языки.'), ('.Вот', 'кошмар-то'), ('.Вы', 'ахуеете'), ('.Прозвучало', 'неубедительно.Учитель'), ('.Спасибо', 'Бердянску'), ('.Хочу', 'миксануть'), ('.ШТА', 'БУДИШЬ'), ('.всё', 'неполноценность.я'), ('.выражаешься', '.то'), ('.горло', 'плохое.живот')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import collocations \n",
    "nltk.download('genesis')\n",
    "\n",
    "print(type(nltk.corpus.genesis.words('english-web.txt')))\n",
    "bigram_measures = collocations.BigramAssocMeasures()\n",
    "# bigram_finder.apply_freq_filter(5)\n",
    "bigram_finder = collocations.BigramCollocationFinder.from_documents([nltk.word_tokenize(x) for x in x_train])\n",
    "bigrams = bigram_finder.nbest(bigram_measures.pmi, 100)\n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_h4Cq1PUTTc-"
   },
   "source": [
    "Можно рассмотреть другие метрики оценки важности биграмм, например, метрику правдоподобия (подробнее про вычисление метрики можно посмотреть [здесь (пункт 5.3.4)](http://www.corpus.unam.mx/cursoenah/ManningSchutze_1999_FoundationsofStatisticalNaturalLanguageProcessing.pdf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lTOJg4KoOo84",
    "outputId": "45d38953-84e0-4a65-fccd-1e96fd83c3f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('(', '('), ('RT', '@'), (')', ')'), ('http', ':'), ('!', '!'), (':', 'D'), ('у', 'меня'), (':', '('), (',', 'а'), (',', 'что'), (',', 'но'), (')', 'http'), ('*', '*'), (':', ')'), ('у', 'нас'), ('(', ','), (',', '('), ('не', 'могу'), ('?', '?'), (':', '-'), (',', ')'), (')', ','), (',', ':'), (',', ','), ('@', '('), (':', ','), ('(', ':'), ('@', ')'), ('@', ','), ('&', 'lt'), ('со', 'мной'), ('@', ':'), ('(', '@'), (':', ':'), (';', ')'), ('новый', 'год'), (':', '*'), ('не', 'знаю'), (')', ':'), ('gt', ';'), (',', '@'), ('сих', 'пор'), ('а', 'я'), ('@', '@'), ('У', 'меня'), (',', 'когда'), ('lt', ';'), ('потому', 'что'), ('&', 'gt'), (';', '('), ('у', 'тебя'), ('все', 'равно'), ('с', 'тобой'), (',', 'как'), ('в', 'школу'), ('(', 'http'), ('ничего', 'не'), ('Как', 'же'), (',', 'я'), (')', '@'), ('Доброе', 'утро'), ('-', ')'), ('я', 'не'), ('--', '--'), (':', 'DD'), ('&', 'amp'), ('не', '('), ('до', 'сих'), ('самом', 'деле'), ('не', ')'), ('как', 'же'), (',', 'чтобы'), (',', '!'), ('(', '!'), ('об', 'этом'), ('что', 'я'), ('не', ':'), ('с', 'кем'), ('никто', 'не'), ('и', '('), ('D', 'http'), ('!', ','), ('.', 'А'), ('amp', ';'), (':', '!'), ('=', ')'), ('?', '—'), (':', '|'), ('и', ')'), ('а', 'потом'), ('никогда', 'не'), ('#', 'євромайдан'), (',', '.'), ('.', ','), ('в', 'этом'), ('@', 'не'), ('не', '@'), ('.', 'Но'), ('@', '!'), ('Новый', 'год')]\n"
     ]
    }
   ],
   "source": [
    "bigrams = bigram_finder.nbest(bigram_measures.likelihood_ratio, 100)\n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfjCYZa8TeX_"
   },
   "source": [
    "Как можно заметить, немаловажную роль в текстах занимает пунктуация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AJk1B39LVRP"
   },
   "source": [
    "## Стоп-слова и пунктуация\n",
    "\n",
    "*Стоп-слова* -- это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе, то есть играют роль шума. Поэтому их принято убирать. По той же причине убирают и пунктуацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fpWhsTuRLVRP",
    "outputId": "1cd18efe-a3cd-4f56-ec4c-bec8b6ee442e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dany\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# у вас здесь, вероятно, выскочит ошибка и надо будет загрузить стоп слова (в тексте ошибки написано, как)\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "OdRF7rlyLVRS",
    "outputId": "dd4ce4f0-13d0-4b21-a3a1-b9ecb281894f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "OfXiH98XLVRV"
   },
   "outputs": [],
   "source": [
    "noise = stopwords.words('russian') + list(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtiIhHDMLVRY"
   },
   "source": [
    "В векторизаторах за стоп-слова, логичным образом, отвечает аргумент `stop_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170125, 243529)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZnbarm_LVRY",
    "outputId": "88f40278-165a-46ad-a75e-2e5d8e7e3a4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.75      0.76     28584\n",
      "    positive       0.75      0.77      0.76     28125\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), stop_words=noise)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42, max_iter=170126)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wr934O7yLVRb"
   },
   "source": [
    "Получилось чууть лучше. Что ещё можно сделать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7O_oD1fLVRc"
   },
   "source": [
    "## Лемматизация\n",
    "\n",
    "Лемматизация – это сведение разных форм одного слова к начальной форме – *лемме*. Почему это хорошо?\n",
    "* Во-первых, мы хотим рассматривать как отдельную фичу каждое *слово*, а не каждую его отдельную форму.\n",
    "* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n",
    "\n",
    "Для русского есть два хороших лемматизатора: mystem и pymorphy:\n",
    "\n",
    "### [Mystem](https://tech.yandex.ru/mystem/)\n",
    "Как с ним работать:\n",
    "* можно скачать mystem и запускать [из терминала с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
    "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96HdoB7zLVRc",
    "outputId": "987397bc-55cb-4830-c361-5568f1f2e015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-09-09 13:19:45--  http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
      "Resolving download.cdn.yandex.net (download.cdn.yandex.net)... 5.45.205.244, 5.45.205.243, 5.45.205.245, ...\n",
      "Connecting to download.cdn.yandex.net (download.cdn.yandex.net)|5.45.205.244|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cachev2-spb03.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz?lid=122 [following]\n",
      "--2021-09-09 13:19:46--  https://cachev2-spb03.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz?lid=122\n",
      "Resolving cachev2-spb03.cdn.yandex.net (cachev2-spb03.cdn.yandex.net)... 37.140.137.3, 2a02:6b8:0:2221::303\n",
      "Connecting to cachev2-spb03.cdn.yandex.net (cachev2-spb03.cdn.yandex.net)|37.140.137.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16457938 (16M) [application/octet-stream]\n",
      "Saving to: ‘mystem-3.0-linux3.1-64bit.tar.gz.1’\n",
      "\n",
      "mystem-3.0-linux3.1 100%[===================>]  15.70M  9.80MB/s    in 1.6s    \n",
      "\n",
      "2021-09-09 13:19:49 (9.80 MB/s) - ‘mystem-3.0-linux3.1-64bit.tar.gz.1’ saved [16457938/16457938]\n",
      "\n",
      "mystem\n"
     ]
    }
   ],
   "source": [
    "!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!cp mystem /bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzQwGwAaZWV5"
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem_analyzer = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_w-_fkNtLVRf"
   },
   "source": [
    "Мы инициализировали Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
    "* mystem_bin - путь к `mystem`, если их несколько\n",
    "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
    "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
    "* entire_input - нужно ли сохранять в выводе все (пробелы всякие, например), или можно выкинуть (по дефолту оставляется все)\n",
    "\n",
    "Методы Mystem принимают строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
    "\n",
    "Можно просто лемматизировать текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjHHLQv9txDq",
    "outputId": "35bcb3cc-7853-48bf-d38d-04157f45221d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['но', ' ', 'не', ' ', 'каждый', ' ', 'хотеть', ' ', 'что-то', ' ', 'исправлять', ':(\\n']\n"
     ]
    }
   ],
   "source": [
    "print(mystem_analyzer.lemmatize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RI1eftjkLVRi"
   },
   "source": [
    "А можно получить грамматическую информацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j4MLqlZnxNEj",
    "outputId": "ffb676bb-932e-4579-817a-c15616431521"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'gr': 'CONJ=', 'lex': 'но', 'wt': 0.9998906255}],\n",
       "  'text': 'Но'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'PART=', 'lex': 'не', 'wt': 1}], 'text': 'не'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'APRO=(вин,ед,муж,неод|им,ед,муж)',\n",
       "    'lex': 'каждый',\n",
       "    'wt': 0.9985975623}],\n",
       "  'text': 'каждый'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'V,несов,пе=непрош,ед,изъяв,3-л',\n",
       "    'lex': 'хотеть',\n",
       "    'wt': 1}],\n",
       "  'text': 'хочет'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'SPRO,ед,сред,неод=(вин|им)', 'lex': 'что-то', 'wt': 1}],\n",
       "  'text': 'что-то'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'V,пе=инф,несов', 'lex': 'исправлять', 'wt': 1}],\n",
       "  'text': 'исправлять'},\n",
       " {'text': ':(\\n'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer.analyze(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADcGtz4JLVRl"
   },
   "source": [
    "Давайте терепь используем лемматизатор майстема в качестве токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x48Q56tiLVRn"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def my_preproc(text):\n",
    "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
    "    text = mystem_analyzer.lemmatize(text)\n",
    "    return [word for word in text if word not in stopwords.words('russian') + [' ', '\\n']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEwOQTJPLVRq",
    "outputId": "b1047a05-9fa7-4994-c947-578cfc4d9825"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.74      0.76     29425\n",
      "    positive       0.73      0.77      0.75     27284\n",
      "\n",
      "    accuracy                           0.75     56709\n",
      "   macro avg       0.75      0.75      0.75     56709\n",
      "weighted avg       0.75      0.75      0.75     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=my_preproc)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJlvqWuALVRs"
   },
   "source": [
    "### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n",
    "Это модуль на питоне, довольно быстрый и с кучей функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tHDkurN1zf7g",
    "outputId": "c9934446-bf72-4603-8a51-9f6ebf406e44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |██████                          | 10 kB 23.5 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 20 kB 25.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 30 kB 12.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 40 kB 9.6 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 51 kB 4.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 55 kB 1.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
      "Collecting dawg-python>=0.7.1\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.2 MB 10.7 MB/s \n",
      "\u001b[?25hInstalling collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7SlwsLU7LVRt"
   },
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "pymorphy2_analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qaz0x7frLVRw"
   },
   "source": [
    "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdf6XoEbLVRw",
    "outputId": "a1984e06-dbeb-4377-896d-b7014b6b84c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='платили', tag=OpencorporaTag('VERB,impf,tran plur,past,indc'), normal_form='платить', score=1.0, methods_stack=((DictionaryAnalyzer(), 'платили', 2472, 10),))]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana = pymorphy2_analyzer.parse(sent[3])\n",
    "ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "0KuHQGPgLVRz",
    "outputId": "3cdbe79d-ec3f-4a07-ff3a-52e8810face1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'платить'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gg0EASPcLVR8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFTkF8xUARlS"
   },
   "source": [
    "### [Natasha](https://github.com/natasha/)\n",
    "\n",
    "В библиотеке natasha реализовано множество полезных библиотек для русского языка: разбиение на токены и предложения, русскоязычные word embeddings, морфологический, синтаксический анализ, лемматизация, извлечение именованных сущностей и т.д. Модуль библиотеки Razdel, основанный на правилах, предназначен для разбиения текста на токены и предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CVeDxeIA6rg",
    "outputId": "ff583009-ae7a-4b68-b6a7-ca1ba48c0732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting razdel\n",
      "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: razdel\n",
      "Successfully installed razdel-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOTkw9MpAnNN",
    "outputId": "51fc6e54-3b82-4c1c-91c2-5b6a60f6304f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(0, 13, 'Кружка-термос'),\n",
       " Substring(14, 16, 'на'),\n",
       " Substring(17, 20, '0.5'),\n",
       " Substring(20, 21, 'л'),\n",
       " Substring(22, 23, '('),\n",
       " Substring(23, 28, '50/64'),\n",
       " Substring(29, 32, 'см³'),\n",
       " Substring(32, 33, ','),\n",
       " Substring(34, 37, '516'),\n",
       " Substring(37, 38, ';'),\n",
       " Substring(38, 41, '...'),\n",
       " Substring(41, 42, ')')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import tokenize\n",
    "\n",
    "tokens = list(tokenize('Кружка-термос на 0.5л (50/64 см³, 516;...)'))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ftx-WzUbBCpO",
    "outputId": "40c67fa4-fab6-4c1b-f651-06951a38798e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Кружка-термос',\n",
       " 'на',\n",
       " '0.5',\n",
       " 'л',\n",
       " '(',\n",
       " '50/64',\n",
       " 'см³',\n",
       " ',',\n",
       " '516',\n",
       " ';',\n",
       " '...',\n",
       " ')']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_.text for _ in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uyhsQp4MGbW8",
    "outputId": "55f84576-aaad-4a68-c5d9-38dc0ea2f721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting natasha\n",
      "  Downloading natasha-1.4.0-py3-none-any.whl (34.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 34.4 MB 30 kB/s \n",
      "\u001b[?25hCollecting ipymarkup>=0.8.0\n",
      "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
      "Collecting navec>=0.9.0\n",
      "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.9.1)\n",
      "Collecting yargy>=0.14.0\n",
      "  Downloading yargy-0.15.0-py3-none-any.whl (41 kB)\n",
      "\u001b[K     |████████████████████████████████| 41 kB 102 kB/s \n",
      "\u001b[?25hCollecting slovnet>=0.3.0\n",
      "  Downloading slovnet-0.5.0-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 4.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: razdel>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.5.0)\n",
      "Collecting intervaltree>=3\n",
      "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec>=0.9.0->natasha) (1.19.5)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
      "Building wheels for collected packages: intervaltree\n",
      "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26119 sha256=c21bb14c19f5774a60e5bb5d903ac3f80d37a2760af69683789029fcfa71fc54\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/85/bd/1001cbb46dcfb71c2001cd7401c6fb250392f22a81ce3722f7\n",
      "Successfully built intervaltree\n",
      "Installing collected packages: navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
      "  Attempting uninstall: intervaltree\n",
      "    Found existing installation: intervaltree 2.1.0\n",
      "    Uninstalling intervaltree-2.1.0:\n",
      "      Successfully uninstalled intervaltree-2.1.0\n",
      "Successfully installed intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.4.0 navec-0.10.0 slovnet-0.5.0 yargy-0.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install natasha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMO3jsqLKSIV"
   },
   "source": [
    "С помощью библиотеки natasha можно также лемматизировать тексты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJZgfRnvIS2q"
   },
   "outputs": [],
   "source": [
    "from natasha import Doc, MorphVocab, Segmenter, NewsEmbedding, NewsMorphTagger\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "\n",
    "def natasha_lemmatize(text):\n",
    "  doc = Doc(text)\n",
    "  doc.segment(segmenter)\n",
    "  doc.tag_morph(morph_tagger)\n",
    "  for token in doc.tokens:\n",
    "    token.lemmatize(morph_vocab)\n",
    "  return {_.text: _.lemma for _ in doc.tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBtlnYlFBOKv",
    "outputId": "47a9e7d6-7f03-4e93-e57c-84dce5657d97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(': '(',\n",
       " ')': ')',\n",
       " ',': ',',\n",
       " '.': '.',\n",
       " '1': '1',\n",
       " '11': '11',\n",
       " '110-летия': '110-летие',\n",
       " '1909': '1909',\n",
       " '1909-1959': '1909-1959',\n",
       " '2010': '2010',\n",
       " '2019': '2019',\n",
       " 'Twitter': 'twitter',\n",
       " '«': '«',\n",
       " '»': '»',\n",
       " 'Бандера': 'бандера',\n",
       " 'Бандере': 'бандера',\n",
       " 'Бандеры': 'бандера',\n",
       " 'В': 'в',\n",
       " 'Верховной': 'верховный',\n",
       " 'Виктора': 'виктор',\n",
       " 'Героем': 'герой',\n",
       " 'Героя': 'герой',\n",
       " 'Житомирский': 'житомирский',\n",
       " 'Израиля': 'израиль',\n",
       " 'Йоэль': 'йоэль',\n",
       " 'Лион': 'лион',\n",
       " 'Львовский': 'львовский',\n",
       " 'Львовской': 'львовский',\n",
       " 'ОУН': 'оун',\n",
       " 'Организации': 'организация',\n",
       " 'Парламентарии': 'парламентарий',\n",
       " 'Петру': 'петр',\n",
       " 'Порошенко': 'порошенко',\n",
       " 'Посол': 'посол',\n",
       " 'Рады': 'рада',\n",
       " 'России': 'россия',\n",
       " 'Свое': 'свой',\n",
       " 'Степан': 'степан',\n",
       " 'Степана': 'степан',\n",
       " 'Украина': 'украина',\n",
       " 'Украине': 'украина',\n",
       " 'Украины': 'украина',\n",
       " 'Ющенко': 'ющенко',\n",
       " 'Я': 'я',\n",
       " 'а': 'а',\n",
       " 'аналогичное': 'аналогичный',\n",
       " 'антисемитизмом': 'антисемитизм',\n",
       " 'антисемитских': 'антисемитский',\n",
       " 'бороться': 'бороться',\n",
       " 'борьбе': 'борьба',\n",
       " 'был': 'быть',\n",
       " 'было': 'быть',\n",
       " 'в': 'в',\n",
       " 'вернуть': 'вернуть',\n",
       " 'властей': 'власть',\n",
       " 'впоследствии': 'впоследствии',\n",
       " 'выступающей': 'выступать',\n",
       " 'героем': 'герой',\n",
       " 'год': 'год',\n",
       " 'года': 'год',\n",
       " 'годом': 'год',\n",
       " 'году': 'год',\n",
       " 'государства': 'государство',\n",
       " 'декабря': 'декабрь',\n",
       " 'депутаты': 'депутат',\n",
       " 'деятельностью': 'деятельность',\n",
       " 'дипломат': 'дипломат',\n",
       " 'дня': 'день',\n",
       " 'должна': 'должный',\n",
       " 'евреев': 'еврей',\n",
       " 'за': 'за',\n",
       " 'забывать': 'забывать',\n",
       " 'запрещенной': 'запретить',\n",
       " 'заявление': 'заявление',\n",
       " 'звание': 'звание',\n",
       " 'и': 'и',\n",
       " 'из': 'из',\n",
       " 'информационном': 'информационный',\n",
       " 'исполнителей': 'исполнитель',\n",
       " 'их': 'они',\n",
       " 'июле': 'июль',\n",
       " 'к': 'к',\n",
       " 'как': 'как',\n",
       " 'ксенофобией': 'ксенофобия',\n",
       " 'кто': 'кто',\n",
       " 'лидера': 'лидер',\n",
       " 'лидеров': 'лидер',\n",
       " 'месяца': 'месяц',\n",
       " 'мифов': 'миф',\n",
       " 'могу': 'мочь',\n",
       " 'на': 'на',\n",
       " 'написал': 'написать',\n",
       " 'населением': 'население',\n",
       " 'националистов': 'националист',\n",
       " 'национальным': 'национальный',\n",
       " 'начале': 'начало',\n",
       " 'не': 'не',\n",
       " 'независимого': 'независимый',\n",
       " 'непосредственно': 'непосредственно',\n",
       " 'никоим': 'никой',\n",
       " 'о': 'о',\n",
       " 'области': 'область',\n",
       " 'областной': 'областной',\n",
       " 'образом': 'образ',\n",
       " 'обратились': 'обратиться',\n",
       " 'объявить': 'объявить',\n",
       " 'однако': 'однако',\n",
       " 'одним': 'один',\n",
       " 'он': 'он',\n",
       " 'остановит': 'остановить',\n",
       " 'отменено': 'отменить',\n",
       " 'отмечать': 'отмечать',\n",
       " 'период': 'период',\n",
       " 'подрывной': 'подрывной',\n",
       " 'поле': 'поле',\n",
       " 'помогает': 'помогать',\n",
       " 'поможет': 'помочь',\n",
       " 'понять': 'понять',\n",
       " 'посмертно': 'посмертно',\n",
       " 'почитание': 'почитание',\n",
       " 'празднованием': 'празднование',\n",
       " 'предложением': 'предложение',\n",
       " 'президентства': 'президентство',\n",
       " 'президенту': 'президент',\n",
       " 'преступлениях': 'преступление',\n",
       " 'признался': 'признаться',\n",
       " 'признан': 'признать',\n",
       " 'признание': 'признание',\n",
       " 'принимал': 'принимать',\n",
       " 'принял': 'принять',\n",
       " 'пришел': 'прийти',\n",
       " 'провозгласить': 'провозгласить',\n",
       " 'пропагандой': 'пропаганда',\n",
       " 'прославление': 'прославление',\n",
       " 'против': 'против',\n",
       " 'разместил': 'разместить',\n",
       " 'распространение': 'распространение',\n",
       " 'регионе': 'регион',\n",
       " 'решение': 'решение',\n",
       " 'решении': 'решение',\n",
       " 'родился': 'родиться',\n",
       " 'рождения': 'рождение',\n",
       " 'российской': 'российский',\n",
       " 'с': 'с',\n",
       " 'связи': 'связь',\n",
       " 'со': 'с',\n",
       " 'совершенных': 'совершить',\n",
       " 'совет': 'совет',\n",
       " 'создание': 'создание',\n",
       " 'созданных': 'создать',\n",
       " 'страны': 'страна',\n",
       " 'судом': 'суд',\n",
       " 'также': 'также',\n",
       " 'территориях': 'территория',\n",
       " 'тех': 'тот',\n",
       " 'уверены': 'уверить',\n",
       " 'ужасных': 'ужасный',\n",
       " 'узнав': 'узнать',\n",
       " 'украиноязычным': 'украиноязычный',\n",
       " 'украинских': 'украинский',\n",
       " 'участие': 'участие',\n",
       " 'через': 'через',\n",
       " 'что': 'что',\n",
       " 'шок': 'шок',\n",
       " 'это': 'это',\n",
       " 'января': 'январь',\n",
       " '—': '—'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Посол Израиля на Украине Йоэль Лион признался, что пришел в шок, узнав о решении властей Львовской области объявить 2019 год годом лидера запрещенной в России Организации украинских националистов (ОУН) Степана Бандеры. Свое заявление он разместил в Twitter. «Я не могу понять, как прославление тех, кто непосредственно принимал участие в ужасных антисемитских преступлениях, помогает бороться с антисемитизмом и ксенофобией. Украина не должна забывать о преступлениях, совершенных против украинских евреев, и никоим образом не отмечать их через почитание их исполнителей», — написал дипломат. 11 декабря Львовский областной совет принял решение провозгласить 2019 год в регионе годом Степана Бандеры в связи с празднованием 110-летия со дня рождения лидера ОУН (Бандера родился 1 января 1909 года). В июле аналогичное решение принял Житомирский областной совет. В начале месяца с предложением к президенту страны Петру Порошенко вернуть Бандере звание Героя Украины обратились депутаты Верховной Рады. Парламентарии уверены, что признание Бандеры национальным героем поможет в борьбе с подрывной деятельностью против Украины в информационном поле, а также остановит «распространение мифов, созданных российской пропагандой». Степан Бандера (1909-1959) был одним из лидеров Организации украинских националистов, выступающей за создание независимого государства на территориях с украиноязычным населением. В 2010 году в период президентства Виктора Ющенко Бандера был посмертно признан Героем Украины, однако впоследствии это решение было отменено судом. '\n",
    "\n",
    "natasha_lemmatize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rck5OVqhLVSA"
   },
   "source": [
    "### mystem vs. pymorphy vs. natasha\n",
    "\n",
    "1) *Мы надеемся, что вы пользуетесь линуксом*, но mystem работает невероятно медленно под windows на больших текстах.\n",
    "\n",
    "2) *Снятие омонимии*. Mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту, natasha тоже с этим тоже не справляется успешно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kH2GQ4ddLVSB"
   },
   "outputs": [],
   "source": [
    "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
    "homonym2 = 'Сорока своровала блестящее украшение со стола.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwF-XsjeI3eX",
    "outputId": "34e9f131-3af5-4a87-9a8c-aa51d6e076ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analysis': [{'lex': 'сорок', 'wt': 0.8710292578, 'gr': 'NUM=(пр|дат|род|твор)'}], 'text': 'сорока'}\n",
      "{'analysis': [{'lex': 'сорока', 'wt': 0.1210970059, 'gr': 'S,жен,од=им,ед'}], 'text': 'Сорока'}\n"
     ]
    }
   ],
   "source": [
    "mystem_analyzer = Mystem() # инициализирую объект с дефолтными параметрами\n",
    "\n",
    "print(mystem_analyzer.analyze(homonym1)[-5])\n",
    "print(mystem_analyzer.analyze(homonym2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9jezRVlFmDo",
    "outputId": "e2224fd9-09e3-428e-fa6a-1af94dcb2ca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'За': 'за', 'время': 'время', 'обучения': 'обучение', 'я': 'я', 'прослушал': 'прослушать', 'больше': 'большой', 'сорока': 'сорок', 'курсов': 'курс', '.': '.'}\n"
     ]
    }
   ],
   "source": [
    "print(natasha_lemmatize(homonym1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXjGBQPoI9gl",
    "outputId": "049fe8af-e0c5-499f-cc10-6d05b047a168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Сорока': 'сорок', 'своровала': 'своровать', 'блестящее': 'блестящий', 'украшение': 'украшение', 'со': 'с', 'стола': 'стол', '.': '.'}\n"
     ]
    }
   ],
   "source": [
    "print(natasha_lemmatize(homonym2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aP5qFnilLVSI"
   },
   "source": [
    "## Словарь, закон Ципфа и закон Хипса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1umtd3OLVSI"
   },
   "source": [
    "Закон Ципфа -- эмпирическая закономерность: если все слова корпуса текста упорядочить по убыванию частоты их использования, то частота n-го слова в таком списке окажется приблизительно обратно пропорциональной его порядковому номеру n. Иными словами, частотность слов убывает очень быстро."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "lY0cWJ7eLVSJ"
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vIjqSVjpLVSL",
    "outputId": "a75ec748-ab21-4bd0-cd41-5a9fa8362b22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2870536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['first_timee', 'хоть', 'я', 'и', 'школота', 'но', 'поверь', 'у', 'нас', 'то']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [token for tweet in df.text for token in nltk.word_tokenize(tweet) if token not in punctuation]\n",
    "print(len(corpus))\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "_oWC7NpkLVSO",
    "outputId": "965b9fbd-6328-4c13-f20f-cd3714d1adb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('не', 69472),\n",
       " ('и', 55166),\n",
       " ('в', 52902),\n",
       " ('я', 52818),\n",
       " ('RT', 38070),\n",
       " ('на', 35759),\n",
       " ('http', 32998),\n",
       " ('что', 31541),\n",
       " ('с', 27217),\n",
       " ('а', 26860)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = Counter(corpus)\n",
    "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
    "list(freq_dict_sorted)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "FrPkce0SLVSQ",
    "outputId": "d2ab5675-433a-480a-90ee-fa5dd9890922"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "first_100_freqs = [freq for word, freq in freq_dict_sorted[:1000]]\n",
    "plt.plot(first_100_freqs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_N5V_K-LVSU"
   },
   "source": [
    "Закон Хипса -- обратная сторона закона Ципфа. Он описывает, что чем больше корпус, тем меньше новых слов добавляется с добавлением новых текстов. В какой-то момент корпус насыщается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dw0GieJSMU-O"
   },
   "source": [
    "## Задание 1.\n",
    "\n",
    "**Задание**: обучите три классификатора: \n",
    "\n",
    "1) на токенах с высокой частотой \n",
    "\n",
    "2) на токенах со средней частотой \n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. на токенах с высокой частотой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "QUQ6kAgPMqNn"
   },
   "outputs": [],
   "source": [
    "freq_threshold = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = Counter([token for tweet in df.text for token in nltk.word_tokenize(tweet) if token not in punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_freq_tokens = [token for token, count in token_counts.items() if count >= freq_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(vocabulary=high_freq_tokens,  lowercase=False)\n",
    "bow = vec.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.60      0.52     20981\n",
      "    positive       0.71      0.57      0.63     35728\n",
      "\n",
      "    accuracy                           0.58     56709\n",
      "   macro avg       0.58      0.59      0.57     56709\n",
      "weighted avg       0.61      0.58      0.59     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. на токенах со средней частотой|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_threshold_up = 10000\n",
    "freq_threshold_down = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = Counter([token for tweet in df.text for token in nltk.word_tokenize(tweet) if token not in punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_freq_tokens = [token for token, count in token_counts.items() if count >= freq_threshold_down and count<=freq_threshold_up]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer(vocabulary=middle_freq_tokens,  lowercase=False)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.24      0.58      0.34     11714\n",
      "    positive       0.83      0.53      0.65     44995\n",
      "\n",
      "    accuracy                           0.54     56709\n",
      "   macro avg       0.54      0.56      0.50     56709\n",
      "weighted avg       0.71      0.54      0.59     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. на токенах со средней частотой|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_threshold = 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_freq_tokens = [token for token, count in token_counts.items() if count <= freq_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351045"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(low_freq_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=351046)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=351046)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=351046)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer(vocabulary=low_freq_tokens,  lowercase=False)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(max_iter=351046)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.75      0.76     28570\n",
      "    positive       0.75      0.77      0.76     28139\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "был взят достаточно высокий порог для первых двух типов данных по частотности, поэтому вышло около 30 слов в первом и втором случае, что повлияло на точность модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mV3fmzp-LVSU"
   },
   "source": [
    "## О важности эксплоративного анализа\n",
    "\n",
    "Но иногда пунктуация бывает и не шумом -- главное отталкиваться от задачи. Что будет если вообще не убирать пунктуацию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Apply any additional tokenization steps here\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "qjkMxK9VLVSV",
    "outputId": "dfea56d5-4d92-4862-9788-29c8c8db29ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dany\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     27819\n",
      "    positive       1.00      1.00      1.00     28890\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=my_tokenizer)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2fRbUAvLVSX"
   },
   "source": [
    "Шок! Стоило оставить пунктуацию -- и все метрики равны 1. Как это получилось? Среди неё были очень значимые токены (как вы думаете, какие?). Найдите фичи с самыми большими коэффициэнтами:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.\n",
    "\n",
    "найти фичи с наибольшей значимостью, и вывести их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vec.get_feature_names_out()\n",
    "coef = clf.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "b_JRuyuRLVSY"
   },
   "outputs": [],
   "source": [
    "coef_dict = dict(zip(feature_names, coef))\n",
    "top_features = sorted(coef_dict.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ") 58.445571349175445\n",
      "d 26.92368588523117\n",
      "dd 10.525564656761699\n",
      "^_^ 9.377724907318662\n",
      "ddd 7.8314933578964805\n",
      "-d 7.592653651135805\n",
      "* 7.238544049785011\n",
      ": 6.186687354746176\n",
      "dddd 4.7589483773119685\n",
      "ddddd 3.3025870427542694\n"
     ]
    }
   ],
   "source": [
    "for feature, coef in top_features:\n",
    "    print(feature, coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vtAyItvLVSb"
   },
   "source": [
    "Посмотрим, как один из супер-значительных токенов справится с классификацией безо всякого машинного обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "uqH07o-7LVSc",
    "outputId": "fad0a24a-98ee-4f84-8782-495548eb0fb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92     32734\n",
      "    positive       0.83      1.00      0.91     23975\n",
      "\n",
      "    accuracy                           0.91     56709\n",
      "   macro avg       0.92      0.93      0.91     56709\n",
      "weighted avg       0.93      0.91      0.91     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cool_token = ')'\n",
    "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5THCOjMLVSg"
   },
   "source": [
    "## Символьные n-граммы\n",
    "\n",
    "Теперь в качестве фичей используем, например, униграммы символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIUwDOabLVSh",
    "outputId": "54f129b1-994f-448e-e861-1912b4a21cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.99      1.00      1.00     27667\n",
      "   positive       1.00      0.99      1.00     29042\n",
      "\n",
      "avg / total       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_E0uPpgLVSj"
   },
   "source": [
    "В общем-то, теперь уже понятно, почему на этих данных здесь 1. Так или инчае, на символах классифицировать тоже можно: для некторых задач (например, для определения языка) фичи-символьные n-граммы решительно рулят.\n",
    "\n",
    "Ещё одна замечательная особенность фичей-символов: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готвых анализаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание\n",
    "\n",
    "все материалы для выполения дз в `sem2.ipynb`\n",
    "\n",
    "\n",
    "### Задание 1.\n",
    "\n",
    "**Задание**: обучите три классификатора: \n",
    "\n",
    "1) на токенах с высокой частотой \n",
    "\n",
    "2) на токенах со средней частотой \n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации.\n",
    "\n",
    "\n",
    "### Задание 2.\n",
    "\n",
    "найти фичи с наибольшей значимостью, и вывести их\n",
    "\n",
    "\n",
    "### Задание 3.\n",
    "\n",
    "1) сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)\n",
    "\n",
    "2) подобрать оптимальный размер для hashing векторайзера \n",
    "\n",
    "3) убедиться что для сетки нет переобучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashng vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer', HashingVectorizer()),\n",
    "    ('clf', LogisticRegression(max_iter=540000000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'vectorizer__n_features': [2**16, 2**19],\n",
    "    'clf__C': [1, 0.1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, HashingVectorizer()),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        LogisticRegression(max_iter=540000000))]),\n",
       "             param_grid={&#x27;clf__C&#x27;: [1, 0.1],\n",
       "                         &#x27;vectorizer__n_features&#x27;: [65536, 524288]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, HashingVectorizer()),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        LogisticRegression(max_iter=540000000))]),\n",
       "             param_grid={&#x27;clf__C&#x27;: [1, 0.1],\n",
       "                         &#x27;vectorizer__n_features&#x27;: [65536, 524288]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, HashingVectorizer()),\n",
       "                (&#x27;clf&#x27;, LogisticRegression(max_iter=540000000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HashingVectorizer</label><div class=\"sk-toggleable__content\"><pre>HashingVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=540000000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer', HashingVectorizer()),\n",
       "                                       ('clf',\n",
       "                                        LogisticRegression(max_iter=540000000))]),\n",
       "             param_grid={'clf__C': [1, 0.1],\n",
       "                         'vectorizer__n_features': [65536, 524288]})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'clf__C': 1, 'vectorizer__n_features': 524288}\n",
      "Best score:  0.7455870683321087\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCNN не смог победить ошибку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'binary_crossentropy/Cast' defined at (most recent call last):\n    File \"C:\\Users\\dany\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\dany\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\dany\\anaconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\dany\\anaconda3\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"C:\\Users\\dany\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\dany\\AppData\\Local\\Temp\\ipykernel_26936\\1443009172.py\", line 24, in <module>\n      model.fit(train_padded, y_train, epochs=10, validation_data=(test_padded, y_test))\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 2145, in binary_crossentropy\n      y_true = tf.cast(y_true, y_pred.dtype)\nNode: 'binary_crossentropy/Cast'\nCast string to float is not supported\n\t [[{{node binary_crossentropy/Cast}}]] [Op:__inference_train_function_5411]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     27\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_padded, y_test)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'binary_crossentropy/Cast' defined at (most recent call last):\n    File \"C:\\Users\\dany\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\dany\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\dany\\anaconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\dany\\anaconda3\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"C:\\Users\\dany\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\dany\\AppData\\Local\\Temp\\ipykernel_26936\\1443009172.py\", line 24, in <module>\n      model.fit(train_padded, y_train, epochs=10, validation_data=(test_padded, y_test))\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\dany\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 2145, in binary_crossentropy\n      y_true = tf.cast(y_true, y_pred.dtype)\nNode: 'binary_crossentropy/Cast'\nCast string to float is not supported\n\t [[{{node binary_crossentropy/Cast}}]] [Op:__inference_train_function_5411]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "train_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "train_padded = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=100, truncating=\"post\", padding=\"post\")\n",
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "test_padded = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=100, truncating=\"post\", padding=\"post\")\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=10000, output_dim=16, input_length=100),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "model.fit(train_padded, y_train, epochs=10, validation_data=(test_padded, y_test))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_padded, y_test)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "gJABxhalLVQu",
    "IaQMCGHFLVQ6",
    "5AJk1B39LVRP",
    "RJlvqWuALVRs",
    "rck5OVqhLVSA",
    "mV3fmzp-LVSU",
    "H5THCOjMLVSg",
    "02s2Vh7MLVSj",
    "b1khxRFDLVSm",
    "sfUmWcAQLVSt",
    "BxvtN-3zLVS5",
    "gyrHhYkgLVTB"
   ],
   "name": "sem1_intro_common.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
